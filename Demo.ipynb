{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gpt_index\n",
      "  Downloading gpt_index-0.4.40-py3-none-any.whl (275 kB)\n",
      "\u001b[K     |████████████████████████████████| 275 kB 986 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting openai>=0.26.4\n",
      "  Downloading openai-0.27.2-py3-none-any.whl (70 kB)\n",
      "\u001b[K     |████████████████████████████████| 70 kB 2.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.24.2-cp39-cp39-macosx_11_0_arm64.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 185 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.3.2-cp39-cp39-macosx_11_0_arm64.whl (702 kB)\n",
      "\u001b[K     |████████████████████████████████| 702 kB 658 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dataclasses-json\n",
      "  Downloading dataclasses_json-0.5.7-py3-none-any.whl (25 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-1.5.3-cp39-cp39-macosx_11_0_arm64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 696 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting langchain\n",
      "  Downloading langchain-0.0.123-py3-none-any.whl (426 kB)\n",
      "\u001b[K     |████████████████████████████████| 426 kB 959 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp39-cp39-macosx_11_0_arm64.whl (338 kB)\n",
      "\u001b[K     |████████████████████████████████| 338 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>=2.20\n",
      "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tqdm\n",
      "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "\u001b[K     |████████████████████████████████| 77 kB 1.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: idna<4,>=2.5 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from requests>=2.20->openai>=0.26.4->gpt_index) (3.4)\n",
      "Collecting certifi>=2017.4.17\n",
      "  Downloading certifi-2022.12.7-py3-none-any.whl (155 kB)\n",
      "\u001b[K     |████████████████████████████████| 155 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<1.27,>=1.21.1\n",
      "  Downloading urllib3-1.26.15-py2.py3-none-any.whl (140 kB)\n",
      "\u001b[K     |████████████████████████████████| 140 kB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.1.0-cp39-cp39-macosx_11_0_arm64.whl (122 kB)\n",
      "\u001b[K     |████████████████████████████████| 122 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp39-cp39-macosx_11_0_arm64.whl (35 kB)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp39-cp39-macosx_11_0_arm64.whl (57 kB)\n",
      "\u001b[K     |████████████████████████████████| 57 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp->openai>=0.26.4->gpt_index) (22.2.0)\n",
      "Collecting marshmallow-enum<2.0.0,>=1.5.1\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0\n",
      "  Downloading typing_inspect-0.8.0-py3-none-any.whl (8.7 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[K     |████████████████████████████████| 49 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=17.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json->gpt_index) (23.0)\n",
      "Collecting typing-extensions>=3.7.4\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting SQLAlchemy<2,>=1\n",
      "  Downloading SQLAlchemy-1.4.47.tar.gz (8.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.6 MB 491 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML>=5.4.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain->gpt_index) (6.0)\n",
      "Collecting pydantic<2,>=1\n",
      "  Downloading pydantic-1.10.7-cp39-cp39-macosx_11_0_arm64.whl (2.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.6 MB 267 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from pandas->gpt_index) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2023.2-py2.py3-none-any.whl (502 kB)\n",
      "\u001b[K     |████████████████████████████████| 502 kB 418 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Applications/Xcode.app/Contents/Developer/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->gpt_index) (1.15.0)\n",
      "Collecting regex>=2022.1.18\n",
      "  Downloading regex-2023.3.23-cp39-cp39-macosx_11_0_arm64.whl (288 kB)\n",
      "\u001b[K     |████████████████████████████████| 288 kB 367 kB/s eta 0:00:01\n",
      "\u001b[?25hBuilding wheels for collected packages: SQLAlchemy\n",
      "  Building wheel for SQLAlchemy (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for SQLAlchemy: filename=SQLAlchemy-1.4.47-cp39-cp39-macosx_10_9_universal2.whl size=1579733 sha256=cf9ead5747a19b5248f6ccc9385bd739532f90a4eb756bad762938001742b571\n",
      "  Stored in directory: /Users/subhrajitpramanick/Library/Caches/pip/wheels/18/f3/88/e801a5f9d7cf25acfa02f3022c689a86e903cea71f03cd1217\n",
      "Successfully built SQLAlchemy\n",
      "Installing collected packages: typing-extensions, mypy-extensions, multidict, marshmallow, frozenlist, yarl, urllib3, typing-inspect, marshmallow-enum, charset-normalizer, certifi, async-timeout, aiosignal, tqdm, tenacity, SQLAlchemy, requests, regex, pytz, pydantic, numpy, dataclasses-json, aiohttp, tiktoken, pandas, openai, langchain, gpt-index\n",
      "Successfully installed SQLAlchemy-1.4.47 aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 certifi-2022.12.7 charset-normalizer-3.1.0 dataclasses-json-0.5.7 frozenlist-1.3.3 gpt-index-0.4.40 langchain-0.0.123 marshmallow-3.19.0 marshmallow-enum-1.5.1 multidict-6.0.4 mypy-extensions-1.0.0 numpy-1.24.2 openai-0.27.2 pandas-1.5.3 pydantic-1.10.7 pytz-2023.2 regex-2023.3.23 requests-2.28.2 tenacity-8.2.2 tiktoken-0.3.2 tqdm-4.65.0 typing-extensions-4.5.0 typing-inspect-0.8.0 urllib3-1.26.15 yarl-1.8.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gpt_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: langchain in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (0.0.123)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/subhrajitpramanick/Library/Python/3.9/lib/python/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 23.0.1 is available.\n",
      "You should consider upgrading via the '/Applications/Xcode.app/Contents/Developer/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_index import SimpleDirectoryReader, GPTListIndex, GPTSimpleVectorIndex, LLMPredictor,PromptHelper\n",
    "from langchain import OpenAI\n",
    "import sys\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['OPENAI_API_KEY']=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createVectorIndex(path):\n",
    "    max_input=4096\n",
    "    tokens=256\n",
    "    chunk_size=600\n",
    "    max_chunk_overlap=20\n",
    "\n",
    "    prompt_helper =PromptHelper(max_input,tokens,max_chunk_overlap,chunk_size_limit=chunk_size)\n",
    "\n",
    "    #define LLM\n",
    "    llmPredictor = LLMPredictor(llm=OpenAI(temperature=0,model_name='text-ada-001',max_tokens=tokens))\n",
    "\n",
    "    #load data\n",
    "\n",
    "    docs =SimpleDirectoryReader(path).load_data()\n",
    "\n",
    "    #create vector index\n",
    "    vectorIndex = GPTSimpleVectorIndex(documents=docs,llm_predictor=llmPredictor,prompt_helper=prompt_helper)\n",
    "    vectorIndex.save_to_disk('vectorIndex.json')\n",
    "    return vectorIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total LLM token usage: 0 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [build_index_from_documents] Total embedding token usage: 62379 tokens\n"
     ]
    }
   ],
   "source": [
    "vectorIndex=createVectorIndex('Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answerMe(vectorIndex):\n",
    "    vIndex= GPTSimpleVectorIndex.load_from_disk(vectorIndex)\n",
    "    while True:\n",
    "        prompt =input('Please ask: ')\n",
    "        response = vIndex.query(prompt,response_mode='compact')\n",
    "        print(f'Response: {response} \\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 652 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 5 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "This book is an eBook from Project Gutenberg, a collection of free eBooks. It is a story about a person who holds out their hand to someone and the person takes it, but is unable to speak. The book is not protected by U.S. copyright law, so it can be copied and distributed without permission or paying royalties. It can also be modified and printed and given away. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 631 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 2 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "I continued on my way, walking faster than usual, with joy in my heart. I knew the sun was setting and the sky was being painted with beautiful colors, but I didn't stop to look. Instead, I kept going, heading towards my chosen hunting ground. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gpt_index.token_counter.token_counter:> [query] Total LLM token usage: 681 tokens\n",
      "INFO:gpt_index.token_counter.token_counter:> [query] Total embedding token usage: 7 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: \n",
      "From this book, we can learn about the relationship between Adam and Eve, and how they interact with each other. We can also learn about the importance of the tide and how it affects their daily lives. Additionally, we can learn about Adam's appreciation for art and beauty, and how he admires the sunsets. Finally, we can learn about Eve's sense of humor and her willingness to learn. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n",
      "INFO:openai:error_code=None error_message=\"[''] is not valid under any of the given schemas - 'input'\" error_param=None error_type=invalid_request_error message='OpenAI API error received' stream_error=False\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m answerMe(\u001b[39m'\u001b[39;49m\u001b[39mvectorIndex.json\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "Cell \u001b[0;32mIn[43], line 5\u001b[0m, in \u001b[0;36manswerMe\u001b[0;34m(vectorIndex)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m      4\u001b[0m     prompt \u001b[39m=\u001b[39m\u001b[39minput\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mPlease ask: \u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m     response \u001b[39m=\u001b[39m vIndex\u001b[39m.\u001b[39;49mquery(prompt,response_mode\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcompact\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mResponse: \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/base.py:424\u001b[0m, in \u001b[0;36mBaseGPTIndex.query\u001b[0;34m(self, query_str, mode, query_transform, use_async, **query_kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m query_config \u001b[39m=\u001b[39m QueryConfig(\n\u001b[1;32m    409\u001b[0m     index_struct_type\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_struct\u001b[39m.\u001b[39mget_type(),\n\u001b[1;32m    410\u001b[0m     query_mode\u001b[39m=\u001b[39mmode_enum,\n\u001b[1;32m    411\u001b[0m     query_kwargs\u001b[39m=\u001b[39mquery_kwargs,\n\u001b[1;32m    412\u001b[0m )\n\u001b[1;32m    413\u001b[0m query_runner \u001b[39m=\u001b[39m QueryRunner(\n\u001b[1;32m    414\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_llm_predictor,\n\u001b[1;32m    415\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prompt_helper,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    422\u001b[0m     use_async\u001b[39m=\u001b[39muse_async,\n\u001b[1;32m    423\u001b[0m )\n\u001b[0;32m--> 424\u001b[0m \u001b[39mreturn\u001b[39;00m query_runner\u001b[39m.\u001b[39;49mquery(query_str, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_index_struct)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/query_runner.py:183\u001b[0m, in \u001b[0;36mQueryRunner.query\u001b[0;34m(self, query_str_or_bundle, index_struct)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    181\u001b[0m     query_bundle \u001b[39m=\u001b[39m query_str_or_bundle\n\u001b[0;32m--> 183\u001b[0m \u001b[39mreturn\u001b[39;00m query_combiner\u001b[39m.\u001b[39;49mrun(query_obj, query_bundle)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/query_combiner/base.py:65\u001b[0m, in \u001b[0;36mSingleQueryCombiner.run\u001b[0;34m(self, query_obj, query_bundle)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Run query combiner.\"\"\"\u001b[39;00m\n\u001b[1;32m     64\u001b[0m updated_query_bundle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_update(query_bundle)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m query_obj\u001b[39m.\u001b[39;49mquery(updated_query_bundle)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/token_counter/token_counter.py:86\u001b[0m, in \u001b[0;36mllm_token_counter.<locals>.wrap.<locals>.wrapped_llm_predict\u001b[0;34m(_self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_llm_predict\u001b[39m(_self: Any, \u001b[39m*\u001b[39margs: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m     85\u001b[0m     \u001b[39mwith\u001b[39;00m wrapper_logic(_self):\n\u001b[0;32m---> 86\u001b[0m         f_return_val \u001b[39m=\u001b[39m f(_self, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     88\u001b[0m     \u001b[39mreturn\u001b[39;00m f_return_val\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/base.py:516\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[39m@llm_token_counter\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    514\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mquery\u001b[39m(\u001b[39mself\u001b[39m, query_bundle: QueryBundle) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m RESPONSE_TYPE:\n\u001b[1;32m    515\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_query(query_bundle)\n\u001b[1;32m    517\u001b[0m     \u001b[39m# if include_summary is True, then include summary text in answer\u001b[39;00m\n\u001b[1;32m    518\u001b[0m     \u001b[39m# summary text is set through `set_text` on the underlying index.\u001b[39;00m\n\u001b[1;32m    519\u001b[0m     \u001b[39m# TODO: refactor response builder to be in the __init__\u001b[39;00m\n\u001b[1;32m    520\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_response_mode \u001b[39m!=\u001b[39m ResponseMode\u001b[39m.\u001b[39mNO_TEXT \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_include_summary:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/base.py:458\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery._query\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Answer a query.\"\"\"\u001b[39;00m\n\u001b[1;32m    457\u001b[0m \u001b[39m# TODO: remove _query and just use query\u001b[39;00m\n\u001b[0;32m--> 458\u001b[0m node_tuples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_nodes_and_similarities_for_response(query_bundle)\n\u001b[1;32m    459\u001b[0m text_tuples \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_text_tuples_from_nodes(\n\u001b[1;32m    460\u001b[0m     query_bundle, [t[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m node_tuples]\n\u001b[1;32m    461\u001b[0m )\n\u001b[1;32m    463\u001b[0m \u001b[39m# prepare response builder\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/base.py:358\u001b[0m, in \u001b[0;36mBaseGPTIndexQuery.get_nodes_and_similarities_for_response\u001b[0;34m(self, query_bundle)\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get list of tuples of node and similarity for response.\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \n\u001b[1;32m    353\u001b[0m \u001b[39mFirst part of the tuple is the node.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mSecond part of tuple is the distance from query to the node.\u001b[39;00m\n\u001b[1;32m    355\u001b[0m \u001b[39mIf not applicable, it's None.\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    357\u001b[0m similarity_tracker \u001b[39m=\u001b[39m SimilarityTracker()\n\u001b[0;32m--> 358\u001b[0m nodes \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_nodes_for_response(\n\u001b[1;32m    359\u001b[0m     query_bundle, similarity_tracker\u001b[39m=\u001b[39;49msimilarity_tracker\n\u001b[1;32m    360\u001b[0m )\n\u001b[1;32m    362\u001b[0m postprocess_info \u001b[39m=\u001b[39m {\u001b[39m\"\u001b[39m\u001b[39msimilarity_tracker\u001b[39m\u001b[39m\"\u001b[39m: similarity_tracker}\n\u001b[1;32m    363\u001b[0m \u001b[39mfor\u001b[39;00m node_processor \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_preprocessors:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/indices/query/vector_store/base.py:49\u001b[0m, in \u001b[0;36mGPTVectorStoreIndexQuery._get_nodes_for_response\u001b[0;34m(self, query_bundle, similarity_tracker)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mis_embedding_query:\n\u001b[1;32m     47\u001b[0m     \u001b[39mif\u001b[39;00m query_bundle\u001b[39m.\u001b[39membedding \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     48\u001b[0m         query_bundle\u001b[39m.\u001b[39membedding \u001b[39m=\u001b[39m (\n\u001b[0;32m---> 49\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_embed_model\u001b[39m.\u001b[39;49mget_agg_embedding_from_queries(\n\u001b[1;32m     50\u001b[0m                 query_bundle\u001b[39m.\u001b[39;49membedding_strs\n\u001b[1;32m     51\u001b[0m             )\n\u001b[1;32m     52\u001b[0m         )\n\u001b[1;32m     53\u001b[0m     query_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_vector_store\u001b[39m.\u001b[39mquery(\n\u001b[1;32m     54\u001b[0m         query_bundle\u001b[39m.\u001b[39membedding,\n\u001b[1;32m     55\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_similarity_top_k,\n\u001b[1;32m     56\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_doc_ids,\n\u001b[1;32m     57\u001b[0m     )\n\u001b[1;32m     58\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     59\u001b[0m     \u001b[39m# TODO: fix function signature of query\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/embeddings/base.py:79\u001b[0m, in \u001b[0;36mBaseEmbedding.get_agg_embedding_from_queries\u001b[0;34m(self, queries, agg_fn)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_query_embedding(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m     80\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[1;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/embeddings/base.py:79\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_agg_embedding_from_queries\u001b[39m(\n\u001b[1;32m     74\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     75\u001b[0m     queries: List[\u001b[39mstr\u001b[39m],\n\u001b[1;32m     76\u001b[0m     agg_fn: Optional[Callable[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m, List[\u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m     77\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m     78\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get aggregated embedding from multiple queries.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 79\u001b[0m     query_embeddings \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_query_embedding(query) \u001b[39mfor\u001b[39;00m query \u001b[39min\u001b[39;00m queries]\n\u001b[1;32m     80\u001b[0m     agg_fn \u001b[39m=\u001b[39m agg_fn \u001b[39mor\u001b[39;00m mean_agg\n\u001b[1;32m     81\u001b[0m     \u001b[39mreturn\u001b[39;00m agg_fn(query_embeddings)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/embeddings/base.py:68\u001b[0m, in \u001b[0;36mBaseEmbedding.get_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_query_embedding\u001b[39m(\u001b[39mself\u001b[39m, query: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m List[\u001b[39mfloat\u001b[39m]:\n\u001b[1;32m     67\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get query embedding.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 68\u001b[0m     query_embedding \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_query_embedding(query)\n\u001b[1;32m     69\u001b[0m     query_tokens_count \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer(query))\n\u001b[1;32m     70\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_total_tokens_used \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m query_tokens_count\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/gpt_index/embeddings/openai.py:223\u001b[0m, in \u001b[0;36mOpenAIEmbedding._get_query_embedding\u001b[0;34m(self, query)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid mode, model combination: \u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    222\u001b[0m     engine \u001b[39m=\u001b[39m _QUERY_MODE_MODEL_DICT[key]\n\u001b[0;32m--> 223\u001b[0m \u001b[39mreturn\u001b[39;00m get_embedding(query, engine\u001b[39m=\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[1;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[0;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[1;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[0;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[1;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/tenacity/nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[0;34m(seconds)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "answerMe('vectorIndex.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
